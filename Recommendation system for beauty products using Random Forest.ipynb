{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b0d52b1",
   "metadata": {},
   "source": [
    "# 1. Importing basic libraries and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56b5b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dc0c4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Product_Name              Brand        Category Usage_Frequency  \\\n",
      "0   Ultra Face Mask     Drunk Elephant           Blush          Weekly   \n",
      "1    Ultra Lipstick      Laura Mercier  Makeup Remover      Occasional   \n",
      "2       Ultra Serum     Natasha Denona     Highlighter           Daily   \n",
      "3      Divine Serum        Ilia Beauty       Face Mask      Occasional   \n",
      "4  Super Foundation  Charlotte Tilbury     Highlighter      Occasional   \n",
      "\n",
      "   Price_USD  Rating  Number_of_Reviews Product_Size  Skin_Type Gender_Target  \\\n",
      "0      67.85     1.4                686         30ml  Sensitive        Female   \n",
      "1     116.43     4.2               5483        250ml        Dry        Unisex   \n",
      "2      90.84     1.6               5039        100ml  Sensitive          Male   \n",
      "3      55.17     3.2               6202        250ml     Normal          Male   \n",
      "4     140.56     1.7                297        100ml       Oily        Female   \n",
      "\n",
      "  Packaging_Type Main_Ingredient  Cruelty_Free Country_of_Origin  \n",
      "0           Tube         Retinol         False         Australia  \n",
      "1         Bottle     Shea Butter         False                UK  \n",
      "2        Compact       Aloe Vera          True             Italy  \n",
      "3           Tube        Glycerin          True       South Korea  \n",
      "4        Compact        Glycerin         False           Germany  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('most_used_beauty_cosmetics_products_extended.csv')\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b15c53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Product_Name          object\n",
       "Brand                 object\n",
       "Category              object\n",
       "Usage_Frequency       object\n",
       "Price_USD            float64\n",
       "Rating               float64\n",
       "Number_of_Reviews      int64\n",
       "Product_Size          object\n",
       "Skin_Type             object\n",
       "Gender_Target         object\n",
       "Packaging_Type        object\n",
       "Main_Ingredient       object\n",
       "Cruelty_Free            bool\n",
       "Country_of_Origin     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the datatypes of each column\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b43fd",
   "metadata": {},
   "source": [
    "# 2. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57fb98a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "df = df.drop(columns=['Product_Name', 'Packaging_Type', 'Main_Ingredient', 'Country_of_Origin'])\n",
    "# Remove 'ml' from the back of each product_size entry\n",
    "df['Product_Size'] = df['Product_Size'].str.replace('ml', '').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55738399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Brand        Category Usage_Frequency  Price_USD  Rating  \\\n",
      "0     Drunk Elephant           Blush          Weekly      67.85     1.4   \n",
      "1      Laura Mercier  Makeup Remover      Occasional     116.43     4.2   \n",
      "2     Natasha Denona     Highlighter           Daily      90.84     1.6   \n",
      "3        Ilia Beauty       Face Mask      Occasional      55.17     3.2   \n",
      "4  Charlotte Tilbury     Highlighter      Occasional     140.56     1.7   \n",
      "\n",
      "   Number_of_Reviews  Product_Size  Skin_Type Gender_Target  Cruelty_Free  \n",
      "0                686          30.0  Sensitive        Female         False  \n",
      "1               5483         250.0        Dry        Unisex         False  \n",
      "2               5039         100.0  Sensitive          Male          True  \n",
      "3               6202         250.0     Normal          Male          True  \n",
      "4                297         100.0       Oily        Female         False  \n"
     ]
    }
   ],
   "source": [
    "# Check dataset structure\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26289ee3",
   "metadata": {},
   "source": [
    "# 3. Converting categorical values into numerical values with label encoding and one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffb8337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate label encoding for the Brand column (target)\n",
    "label_encoder_brand = LabelEncoder()\n",
    "df['Brand'] = label_encoder_brand.fit_transform(df['Brand'])\n",
    "\n",
    "# One-hot encoding for categorical columns (inputs)\n",
    "categorical_cols = ['Category', 'Usage_Frequency', 'Skin_Type', 'Gender_Target', 'Cruelty_Free']\n",
    "df = pd.get_dummies(df, columns=categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f562510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Brand  Price_USD  Rating  Number_of_Reviews  Product_Size  \\\n",
      "0      9      67.85     1.4                686          30.0   \n",
      "1     22     116.43     4.2               5483         250.0   \n",
      "2     27      90.84     1.6               5039         100.0   \n",
      "3     17      55.17     3.2               6202         250.0   \n",
      "4      5     140.56     1.7                297         100.0   \n",
      "\n",
      "   Category_BB Cream  Category_Blush  Category_Bronzer  Category_CC Cream  \\\n",
      "0                  0               1                 0                  0   \n",
      "1                  0               0                 0                  0   \n",
      "2                  0               0                 0                  0   \n",
      "3                  0               0                 0                  0   \n",
      "4                  0               0                 0                  0   \n",
      "\n",
      "   Category_Cleanser  ...  Skin_Type_Combination  Skin_Type_Dry  \\\n",
      "0                  0  ...                      0              0   \n",
      "1                  0  ...                      0              1   \n",
      "2                  0  ...                      0              0   \n",
      "3                  0  ...                      0              0   \n",
      "4                  0  ...                      0              0   \n",
      "\n",
      "   Skin_Type_Normal  Skin_Type_Oily  Skin_Type_Sensitive  \\\n",
      "0                 0               0                    1   \n",
      "1                 0               0                    0   \n",
      "2                 0               0                    1   \n",
      "3                 1               0                    0   \n",
      "4                 0               1                    0   \n",
      "\n",
      "   Gender_Target_Female  Gender_Target_Male  Gender_Target_Unisex  \\\n",
      "0                     1                   0                     0   \n",
      "1                     0                   0                     1   \n",
      "2                     0                   1                     0   \n",
      "3                     0                   1                     0   \n",
      "4                     1                   0                     0   \n",
      "\n",
      "   Cruelty_Free_False  Cruelty_Free_True  \n",
      "0                   1                  0  \n",
      "1                   1                  0  \n",
      "2                   0                  1  \n",
      "3                   0                  1  \n",
      "4                   1                  0  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check dataset structure to confirm that one-hot encoding has been applied\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63af1b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Brand                           int32\n",
       "Price_USD                     float64\n",
       "Rating                        float64\n",
       "Number_of_Reviews               int64\n",
       "Product_Size                  float64\n",
       "Category_BB Cream               uint8\n",
       "Category_Blush                  uint8\n",
       "Category_Bronzer                uint8\n",
       "Category_CC Cream               uint8\n",
       "Category_Cleanser               uint8\n",
       "Category_Concealer              uint8\n",
       "Category_Contour                uint8\n",
       "Category_Exfoliator             uint8\n",
       "Category_Eye Shadow             uint8\n",
       "Category_Eyeliner               uint8\n",
       "Category_Face Mask              uint8\n",
       "Category_Face Oil               uint8\n",
       "Category_Foundation             uint8\n",
       "Category_Highlighter            uint8\n",
       "Category_Lip Gloss              uint8\n",
       "Category_Lip Liner              uint8\n",
       "Category_Lipstick               uint8\n",
       "Category_Makeup Remover         uint8\n",
       "Category_Mascara                uint8\n",
       "Category_Moisturizer            uint8\n",
       "Category_Powder                 uint8\n",
       "Category_Primer                 uint8\n",
       "Category_Serum                  uint8\n",
       "Category_Setting Spray          uint8\n",
       "Usage_Frequency_Daily           uint8\n",
       "Usage_Frequency_Monthly         uint8\n",
       "Usage_Frequency_Occasional      uint8\n",
       "Usage_Frequency_Weekly          uint8\n",
       "Skin_Type_Combination           uint8\n",
       "Skin_Type_Dry                   uint8\n",
       "Skin_Type_Normal                uint8\n",
       "Skin_Type_Oily                  uint8\n",
       "Skin_Type_Sensitive             uint8\n",
       "Gender_Target_Female            uint8\n",
       "Gender_Target_Male              uint8\n",
       "Gender_Target_Unisex            uint8\n",
       "Cruelty_Free_False              uint8\n",
       "Cruelty_Free_True               uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the data types had been converted to numerical\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b439a2bc",
   "metadata": {},
   "source": [
    "# 4. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93a25d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (X) and Target (y)\n",
    "X = df.drop(columns=['Brand'])\n",
    "y = df['Brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57628ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a81ccc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffb3ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize the RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c80048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Set up GridSearchCV with cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_model, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5,  # 5-fold cross-validation\n",
    "                           n_jobs=-1,  # Use all available CPU cores\n",
    "                           verbose=2,  # Display progress during the grid search\n",
    "                           scoring='accuracy')  # Optimize for accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "487705fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=30), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'max_depth': [None, 10, 20, 30],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [50, 100, 200]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Fit GridSearchCV to the training data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc7d843b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'bootstrap': False, 'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Output the best parameters found during the grid search\n",
    "print(\"Best Parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "203989ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Make predictions on the test set using the best estimator\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred = best_rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683edb13",
   "metadata": {},
   "source": [
    "# 5. Entering user inputs to obtain recommended brand to buy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed9016ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Category': 'Blush', 'Usage_Frequency': 'Daily', 'Price_USD': 25.99, 'Rating': 4.5, 'Number_of_Reviews': 1000, 'Product_Size': 100, 'Skin_Type': 'Oily', 'Gender_Target': 'Male', 'Cruelty_Free': 'True'}\n"
     ]
    }
   ],
   "source": [
    "# Sample input data (before encoding)\n",
    "sample_input = {\n",
    "    'Category': 'Blush',\n",
    "    'Usage_Frequency': 'Daily',\n",
    "    'Price_USD': 25.99,\n",
    "    'Rating': 4.5,\n",
    "    'Number_of_Reviews': 1000,\n",
    "    'Product_Size': 100,  # in ml, already converted to numeric\n",
    "    'Skin_Type': 'Oily',\n",
    "    'Gender_Target': 'Male',\n",
    "    'Cruelty_Free': 'True'\n",
    "}\n",
    "\n",
    "print(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be1ddf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Brand (Categorical): Danessa Myricks\n"
     ]
    }
   ],
   "source": [
    "# Convert sample_input into a DataFrame\n",
    "input_df = pd.DataFrame([sample_input])\n",
    "\n",
    "# Apply the same one-hot encoding to the input data\n",
    "input_df = pd.get_dummies(input_df)\n",
    "\n",
    "# Align input_df with the training data (ensure columns match)\n",
    "input_df = input_df.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Select the same feature columns as the ones used for training\n",
    "X_new = input_df\n",
    "\n",
    "# Make a prediction with the best model\n",
    "brand_prediction = best_rf_model.predict(X_new)\n",
    "\n",
    "# Convert predicted brand back to categorical\n",
    "predicted_brand_categorical = label_encoder_brand.inverse_transform([brand_prediction[0]])\n",
    "print(\"Predicted Brand (Categorical):\", predicted_brand_categorical[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95277e95",
   "metadata": {},
   "source": [
    "### Therefore with the given sample inputs, the predicted brand to purchase from is Danessa Myricks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1670673",
   "metadata": {},
   "source": [
    "# 6. Analyzing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2811807",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.02      0.02       122\n",
      "           1       0.02      0.04      0.03       104\n",
      "           2       0.03      0.03      0.03       127\n",
      "           3       0.04      0.04      0.04       110\n",
      "           4       0.02      0.01      0.01       104\n",
      "           5       0.05      0.02      0.03       122\n",
      "           6       0.04      0.02      0.03       121\n",
      "           7       0.02      0.01      0.01        96\n",
      "           8       0.04      0.04      0.04        95\n",
      "           9       0.00      0.00      0.00       118\n",
      "          10       0.02      0.02      0.02       132\n",
      "          11       0.02      0.02      0.02       123\n",
      "          12       0.03      0.02      0.02       115\n",
      "          13       0.01      0.01      0.01       116\n",
      "          14       0.01      0.01      0.01       110\n",
      "          15       0.05      0.04      0.05       120\n",
      "          16       0.03      0.01      0.01       109\n",
      "          17       0.02      0.03      0.02       106\n",
      "          18       0.02      0.02      0.02       110\n",
      "          19       0.03      0.05      0.04       110\n",
      "          20       0.03      0.07      0.04       119\n",
      "          21       0.06      0.04      0.05       122\n",
      "          22       0.03      0.02      0.02       106\n",
      "          23       0.03      0.06      0.04       124\n",
      "          24       0.02      0.04      0.03       131\n",
      "          25       0.01      0.01      0.01       120\n",
      "          26       0.02      0.02      0.02       124\n",
      "          27       0.02      0.03      0.03       103\n",
      "          28       0.05      0.02      0.03        99\n",
      "          29       0.00      0.00      0.00        87\n",
      "          30       0.02      0.01      0.01       104\n",
      "          31       0.02      0.02      0.02       119\n",
      "          32       0.02      0.02      0.02       106\n",
      "          33       0.02      0.03      0.02        93\n",
      "          34       0.04      0.05      0.05       112\n",
      "          35       0.03      0.03      0.03        97\n",
      "          36       0.01      0.02      0.02       110\n",
      "          37       0.04      0.04      0.04       110\n",
      "          38       0.03      0.02      0.02       104\n",
      "          39       0.03      0.02      0.03       140\n",
      "\n",
      "    accuracy                           0.03      4500\n",
      "   macro avg       0.03      0.03      0.02      4500\n",
      "weighted avg       0.03      0.03      0.02      4500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83de8569",
   "metadata": {},
   "source": [
    "### The scores are extremely low based on the classification report, signifying a serious problem with the random forest model. In order to find out the issue, we would use the cosine similarity algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "552e2717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X is our feature matrix and y is our target variable\n",
    "y = df[\"Brand\"]\n",
    "unique_labels = np.unique(y)\n",
    "class_features = [X[y == label].mean(axis=0) for label in unique_labels]\n",
    "similarity_matrix = cosine_similarity(class_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ccec3f2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.99999989, 0.99999628, ..., 0.99999955, 0.99999971,\n",
       "        0.99999833],\n",
       "       [0.99999989, 1.        , 0.99999745, ..., 0.99999903, 0.99999925,\n",
       "        0.99999744],\n",
       "       [0.99999628, 0.99999745, 1.        , ..., 0.99999373, 0.99999407,\n",
       "        0.99999067],\n",
       "       ...,\n",
       "       [0.99999955, 0.99999903, 0.99999373, ..., 1.        , 0.99999996,\n",
       "        0.9999996 ],\n",
       "       [0.99999971, 0.99999925, 0.99999407, ..., 0.99999996, 1.        ,\n",
       "        0.99999936],\n",
       "       [0.99999833, 0.99999744, 0.99999067, ..., 0.9999996 , 0.99999936,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876fba1d",
   "metadata": {},
   "source": [
    "### By using the cosine similarity algorithm, we see that the scores are low because the classes are too highly correlated and the model is unable to distinguish between them. As such, using a random forest model is not suitable for this data set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
